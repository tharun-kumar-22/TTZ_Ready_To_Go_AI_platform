# üöÄ TTZ.KT AI Platform 2025 - Local Document Assistant

![Version](https://img.shields.io/badge/version-8.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)
![Python](https://img.shields.io/badge/python-3.8%2B-brightgreen)
![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20Mac%20%7C%20Linux-lightgrey)

**100% Free | 100% Local | 100% Private**

Chat with your documents using powerful AI models - completely offline and private. No API keys, no internet required, no data leaves your computer.

---

## ‚ú® **Features**

- ü§ñ **19 AI Models** - Qwen, DeepSeek, Llama, Mistral, Gemma, Phi, GPT-OSS
- üìÑ **13+ File Formats** - PDF, DOCX, CSV, XLSX, Images, JSON, XML, YAML and more
- üíæ **100% Local Processing** - All data stays on your computer
- üîí **Complete Privacy** - No internet connection needed after setup
- üí∞ **Zero Cost** - No API fees, completely free forever
- ‚ö° **Instant Model Switching** - Change AI models without reprocessing documents
- üéØ **Smart Retrieval** - Advanced RAG (Retrieval Augmented Generation) technology
- üí¨ **Conversational** - Chat naturally with your documents

---

## üìã **What Can You Do?**

- üìö **Research**: Analyze research papers, extract key information
- üíº **Business**: Process reports, analyze data, extract insights
- üìñ **Study**: Learn from textbooks, create summaries, ask questions
- üìä **Data Analysis**: Query CSV/Excel files naturally
- üîç **Document Search**: Find information across multiple documents instantly
- üìù **Content Creation**: Extract quotes, generate summaries

---

## üéØ **Supported File Formats**

| Category | Formats |
|----------|---------|
| üìÑ **Documents** | PDF, DOCX, DOC, TXT, RTF, MD |
| üìä **Spreadsheets** | CSV, XLSX, XLS, ODS |
| üñºÔ∏è **Images** | PNG, JPG, JPEG, BMP, TIFF, GIF |
| üíæ **Data Files** | JSON, XML, YAML, YML |

---

## üöÄ **Quick Start**

### **Prerequisites**
- **Python 3.8+** installed
- **Ollama** installed and running
- **At least one Ollama model** downloaded

### **Installation (5 minutes)**

1. **Download this project**
```bash
   git clone https://github.com/YOUR_USERNAME/TTZ_ready_to_go-olama.git
   cd TTZ_ready_to_go-olama
```

2. **Install Python dependencies**
```bash
   pip install -r requirements.txt
```

3. **Download at least one Ollama model**
```bash
   ollama pull qwen2.5:7b
```

4. **Run the application**
```bash
   streamlit run app.py
```

5. **Open your browser** - The app will automatically open at `http://localhost:8501`

**That's it! üéâ**

---

## üìñ **How to Use**

### **Step 1: Select AI Model**
Choose from your downloaded Ollama models in the sidebar.

**Recommended models:**
- `qwen2.5:7b` - Best balance of speed and accuracy
- `llama3.2:latest` - Fast and efficient
- `deepseek-r1:8b` - Advanced reasoning capabilities

### **Step 2: Upload Documents**
- Click "Choose files" in the sidebar
- Select one or multiple files (PDF, DOCX, CSV, etc.)
- Click "üöÄ Process All Files"

### **Step 3: Ask Questions**
Type your questions in the chat box. Examples:
- "What are the main points in this document?"
- "Summarize the findings in chapter 3"
- "What are all the questions mentioned in the PDF?"
- "Compare the data in these spreadsheets"

### **Step 4: Switch Models (Optional)**
Change AI models anytime without re-uploading documents!

---

## ü§ñ **Available AI Models**

The app supports **19 Ollama models** across 8 families:

### **üåü Qwen Family (7 models)**
- `qwen3:latest`, `qwen3:8b` - Latest 2025 models
- `qwen2.5:latest`, `qwen2.5:7b`, `qwen2.5:3b` - Stable versions
- `qwen3-coder:latest`, `qwen2.5-coder:latest` - Code specialists

### **üß† DeepSeek (2 models)**
- `deepseek-r1:latest`, `deepseek-r1:8b` - Advanced reasoning

### **ü¶ô Llama (2 models)**
- `llama3.2:latest`, `llama3.1:latest` - Meta's powerful models

### **üî• Mistral (1 model)**
- `mistral:latest` - Fast and powerful

### **üíé Gemma (2 models)**
- `gemma3:latest`, `gemma2:latest` - Google's efficient models

### **üß† Phi (3 models)**
- `phi4:latest`, `phi3.5:latest`, `phi3:latest` - Microsoft's compact models

### **ü§ñ GPT-OSS (2 models)**
- `gpt-oss:latest`, `gpt-oss:20b` - OpenAI-style open source

**Download models with:**
```bash
ollama pull model-name
```

---

## üí° **Tips for Best Results**

1. **Model Selection**
   - Start with `qwen2.5:7b` for balanced performance
   - Use `deepseek-r1:8b` for complex reasoning tasks
   - Try `llama3.2` for faster responses

2. **Document Upload**
   - Upload related documents together for better context
   - Clear and well-formatted documents work best
   - Process multiple files at once to compare information

3. **Asking Questions**
   - Be specific in your questions
   - Ask follow-up questions for deeper insights
   - Use "list all..." for comprehensive answers

4. **Performance**
   - First response may be slower (model loading)
   - Subsequent queries are much faster
   - Switch models without reprocessing for instant comparison

---

## üîß **System Requirements**

### **Minimum**
- **CPU**: 4 cores
- **RAM**: 8 GB
- **Storage**: 5 GB free (for models)
- **OS**: Windows 10/11, macOS 10.15+, or Linux

### **Recommended**
- **CPU**: 8+ cores or GPU (NVIDIA/AMD)
- **RAM**: 16 GB+
- **Storage**: 20 GB+ (for multiple models)
- **GPU**: CUDA-compatible (optional, for faster performance)

---

## üõ†Ô∏è **Troubleshooting**

### **"Connection refused" error**
- Ensure Ollama is running: `ollama serve`
- Check Ollama is at `http://localhost:11434`

### **"Model not found" error**
- Download the model first: `ollama pull qwen2.5:7b`
- Check available models: `ollama list`

### **Slow performance**
- Use smaller models (`qwen2.5:3b`, `phi3`)
- Close other applications
- Use GPU if available

### **Import errors**
```bash
pip install -r requirements.txt --upgrade
```

**For detailed troubleshooting**, see [INSTALL.md](INSTALL.md)

---

## üîí **Privacy & Security**

- ‚úÖ **No Internet Required** - Works completely offline after setup
- ‚úÖ **No Data Collection** - Zero telemetry or tracking
- ‚úÖ **No Cloud Storage** - All files processed locally in memory
- ‚úÖ **No API Keys** - No external services or accounts needed
- ‚úÖ **Temporary Files** - Deleted immediately after processing
- ‚úÖ **Your Data, Your Computer** - Complete control and privacy

---

## üìö **Documentation**

- [Installation Guide](INSTALL.md) - Detailed setup instructions
- [Troubleshooting](INSTALL.md#troubleshooting) - Common issues and solutions
- [Model Guide](INSTALL.md#choosing-models) - Which model to use

---

## ü§ù **Contributing**

Contributions are welcome! Feel free to:
- Report bugs
- Suggest features
- Submit pull requests
- Share your experience

---

## üìÑ **License**

MIT License - Free to use for personal and commercial projects.

---

## üåü **Star This Project**

If you find this useful, please give it a ‚≠ê on GitHub!

---

## üìû **Support**

- **Issues**: [GitHub Issues](https://github.com/YOUR_USERNAME/TTZ_ready_to_go-olama/issues)
- **Discussions**: [GitHub Discussions](https://github.com/YOUR_USERNAME/TTZ_ready_to_go-olama/discussions)

---

## üôè **Acknowledgments**

Built with:
- [Ollama](https://ollama.ai/) - Local LLM runtime
- [LangChain](https://www.langchain.com/) - LLM framework
- [Streamlit](https://streamlit.io/) - Web interface
- [FAISS](https://github.com/facebookresearch/faiss) - Vector search
- [HuggingFace](https://huggingface.co/) - Embeddings

---

**Made with ‚ù§Ô∏è for the local AI community**

---

*Last updated: October 2025*
```

---

### **FILE 2: .gitignore**

**Create a new file named `.gitignore` and paste this:**
```
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
env/
ENV/
.venv

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Application specific
vectors/
data/
__pycache__/
*.pyc
.DS_Store
Thumbs.db

# Logs
*.log

# Temporary files
*.tmp
temp/
tmp/

# Environment variables
.env.local
.env.*.local

# Streamlit
.streamlit/secrets.toml
```

---

### **FILE 3: LICENSE**

**Create a new file named `LICENSE` and paste this:**
```
MIT License

Copyright (c) 2025 TTZ.KT

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.